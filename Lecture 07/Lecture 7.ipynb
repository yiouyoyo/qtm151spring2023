{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> Lecture 7: Applications II - Operations with multiple datasets </span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> \n",
    "\n",
    "This class will be entirely self-directed\n",
    "\n",
    "- Learn basic commands for importing/exporting datasets\n",
    "- Practice this module's concepts in a quiz\n",
    "- More info will be posted on Canvas at the start of class\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkblue\"> I. Import Libraries </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the \"numPy\" library is used for mathematical operations\n",
    "# the \"matplotlib\" library is for generating graphs\n",
    "# the \"pandas\" library is for manipualting datasets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkblue\"> II. Importing / Exporting Datasets </span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "There are many formats to store data out there.\n",
    "\n",
    "- So far we've only imported \".csv\" files\n",
    "- Also common: Excel (\".xlsx\") and Stata (\".dta\")\n",
    "- Pandas can handle all these formats! Full list:\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/io.html#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\" >\n",
    "\n",
    "Read/write from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a CSV file (READ)\n",
    "carfeatures = pd.read_csv(\"data/features.csv\")\n",
    "\n",
    "# Save the dataset to another csv file (WRITE)\n",
    "carfeatures.to_csv(\"data/features_stored.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Read/write from Stata (\".dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a Stata file\n",
    "carfeatures = pd.read_stata(\"data/features.dta\")\n",
    "\n",
    "# Write a stata file\n",
    "carfeatures.to_stata(\"data/features_stored.dta\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Read/write from Excel (\".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Read\n",
    "carfeatures = pd.read_excel(\"data/features.xlsx\")\n",
    "\n",
    "# Write \n",
    "carfeatures.to_excel(\"data/features_stored.xlsx\")\n",
    "\n",
    "# Note: If the information is contained in a specifc sheet of the excel file\n",
    "# carfeatures = pd.read_excel(\"data/features.csv\",sheet_name = \"Sheet1\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkblue\"> III. Quiz Structure </span>\n",
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "The day of the quiz I will ...\n",
    "- Provide different datasets with yearly data\n",
    "- Give more specific instructions.\n",
    "- Below, you will see that type of questions that will be asked.\n",
    "- The idea is for you to apply known concepts to new data\n",
    "- You have 50 minutes to complete the assignment\n",
    "\n",
    "Questions\n",
    "\n",
    "(exact wording may change in quiz, but exercise will be very similar)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(a) Create two normal random variables ...\n",
    "\n",
    "\n",
    "- Call them \"vec_x\" and \"vec_z\"\n",
    "- To generate each variable, use loc = 2, scale = 5, size = 1000\n",
    "- Plot a histogram of each variable\n",
    "    - Label the axes and title\n",
    "    - Each graph should have a different title\n",
    " \n",
    "To get full points, plot the histograms on a grid (See Lecture 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mJupyter server crashed. Unable to connect. \n",
      "\u001b[1;31mError code from Jupyter: 1\n",
      "\u001b[1;31musage: jupyter.py [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "\u001b[1;31m                  [--paths] [--json] [--debug]\n",
      "\u001b[1;31m                  [subcommand]\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mJupyter: Interactive Computing\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mpositional arguments:\n",
      "\u001b[1;31m  subcommand     the subcommand to launch\n",
      "\u001b[1;31m\n",
      "\u001b[1;31moptions:\n",
      "\u001b[1;31m  -h, --help     show this help message and exit\n",
      "\u001b[1;31m  --version      show the versions of core jupyter packages and exit\n",
      "\u001b[1;31m  --config-dir   show Jupyter config dir\n",
      "\u001b[1;31m  --data-dir     show Jupyter data dir\n",
      "\u001b[1;31m  --runtime-dir  show Jupyter runtime dir\n",
      "\u001b[1;31m  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "\u001b[1;31m                 format.\n",
      "\u001b[1;31m  --json         output paths as machine-readable json\n",
      "\u001b[1;31m  --debug        output debug information about paths\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mAvailable subcommands: dejavu nbconvert\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mJupyter command `jupyter-notebook` not found. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Generate the normal random variables\n",
    "vec_x = np.random.normal(loc=2, scale=5, size=1000)\n",
    "vec_z = np.random.normal(loc=2, scale=5, size=1000)\n",
    "\n",
    "# Plot the histograms on a grid\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "\n",
    "ax[0].hist(vec_x, bins=20, color='blue', alpha=0.7)\n",
    "ax[0].set_xlabel('x values')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[0].set_title('Histogram of vec_x')\n",
    "\n",
    "ax[1].hist(vec_z, bins=20, color='red', alpha=0.7)\n",
    "ax[1].set_xlabel('z values')\n",
    "ax[1].set_ylabel('Frequency')\n",
    "ax[1].set_title('Histogram of vec_z')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#way 2\n",
    "vec_x = np.random.uniform(low=10, high=20, size=1000)\n",
    "vec_z = np.random.chisquare(df = 1, size = 1000)              fig, list_subfig = plt.subplots(1, 2, figsize = (10,3))\n",
    "plt.tight_layout()\n",
    "list_subfig[0].hist(vec_x)\n",
    "list_subfig[0].set_title(\"vec_x\")\n",
    "list_subfig[0].set_xlabel('x_axis')\n",
    "list_subfig[0].set_ylabel('y_axis')\n",
    "\n",
    "list_subfig[1].hist(vec_z)\n",
    "list_subfig[1].set_title(\"vec_z\")\n",
    "list_subfig[1].set_xlabel('x_axis')\n",
    "list_subfig[1].set_ylabel('y_axis')\n",
    "\n",
    "plt.show\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(b) Create a new variable \"vec_y\" by the formula\n",
    "\n",
    "$ y = x^2 + 2x + 5$\n",
    "\n",
    "- Use element-by-element vector multiplicaiton (no loops)\n",
    "- Produce a scatter plot of \"vec_y\" against \"vec_x\"\n",
    "- Label the axes and the title\n",
    "- Change the color to \"red\", \"green\" or \"purple\" (you choose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mJupyter server crashed. Unable to connect. \n",
      "\u001b[1;31mError code from Jupyter: 1\n",
      "\u001b[1;31musage: jupyter.py [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "\u001b[1;31m                  [--paths] [--json] [--debug]\n",
      "\u001b[1;31m                  [subcommand]\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mJupyter: Interactive Computing\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mpositional arguments:\n",
      "\u001b[1;31m  subcommand     the subcommand to launch\n",
      "\u001b[1;31m\n",
      "\u001b[1;31moptions:\n",
      "\u001b[1;31m  -h, --help     show this help message and exit\n",
      "\u001b[1;31m  --version      show the versions of core jupyter packages and exit\n",
      "\u001b[1;31m  --config-dir   show Jupyter config dir\n",
      "\u001b[1;31m  --data-dir     show Jupyter data dir\n",
      "\u001b[1;31m  --runtime-dir  show Jupyter runtime dir\n",
      "\u001b[1;31m  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "\u001b[1;31m                 format.\n",
      "\u001b[1;31m  --json         output paths as machine-readable json\n",
      "\u001b[1;31m  --debug        output debug information about paths\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mAvailable subcommands: dejavu nbconvert\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mJupyter command `jupyter-notebook` not found. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "vec_y = np.exp(vec_x) + 2*vec_x + 5\n",
    "\n",
    "plt.scatter(vec_x, vec_y, color = \"g\")\n",
    "plt.title(\"vec_y\")\n",
    "plt.xlabel(\"x_axis\")\n",
    "plt.ylabel(\"y_axis\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(c) Creates two lists with ...\n",
    "\n",
    "- The names of the datasets\n",
    "- The years of the datasets (type manually based on the dataset names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_datasets = []\n",
    "list_newnames =  []\n",
    "index = 0\n",
    "for data in list_datasets:\n",
    "    dataset = pd.read_csv(data)\n",
    "    filename = list_newnames[index]\n",
    "    dataset.to_excel( filename, index = None, header=True)\n",
    "    index = index + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(d) Create a loop that ...\n",
    "\n",
    "\n",
    "- Goes over the list of years\n",
    "- If the year $\\ge$ 2010, print the message\n",
    "\n",
    "$\\qquad$ \"This dataset contains information on or after 2010.\n",
    "\n",
    "- If the year $<$ 2010, print the message\n",
    "\n",
    "$\\qquad$ \"This dataset contains information before 2010\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in list_years:\n",
    "    if year >= 2000:\n",
    "        print(\"This dataset contains information on or after 2000\")\n",
    "    else:\n",
    "        print(\"This dataset contains information before 2000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(e) Create a for loop that ...\n",
    "\n",
    "- Reads multiple \".csv\" files and\n",
    "- Converts them to \".xlsx\" files\n",
    "- Note: Make sure to know how to read/write in subfolders\n",
    "\n",
    "Hint: Create a new list with the \".xslx\" names and use a for loop with numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(list_datasets)):\n",
    "    dataset=pd.read_csv(list_datasets[index])\n",
    "    filename = list_newnames[index]\n",
    "    dataset.to_excel(filename, index = None, header=True)\n",
    "    \n",
    "\n",
    "    # Directory where the .csv files are stored\n",
    "dir = \"/path/to/csv/files\"\n",
    "\n",
    "# List all .csv files in the directory\n",
    "csv_files = [f for f in os.listdir(dir) if f.endswith('.csv')]\n",
    "\n",
    "# Create a list to store the names of the converted .xlsx files\n",
    "xlsx_files = []\n",
    "\n",
    "# Loop over all the .csv files\n",
    "for i, csv_file in enumerate(csv_files):\n",
    "    # Read the .csv file into a Pandas DataFrame\n",
    "    df = pd.read_csv(os.path.join(dir, csv_file))\n",
    "    \n",
    "    # Create the name of the corresponding .xlsx file\n",
    "    xlsx_file = csv_file.replace(\".csv\", \".xlsx\")\n",
    "    xlsx_files.append(xlsx_file)\n",
    "    \n",
    "    # Write the DataFrame to the .xlsx file\n",
    "    df.to_excel(os.path.join(dir, xlsx_file), index=False)\n",
    "\n",
    "# Print the names of the converted .xlsx files\n",
    "print(\"Converted the following .csv files to .xlsx:\")\n",
    "for i, xlsx_file in enumerate(xlsx_files):\n",
    "    print(\"{}. {}\".format(i + 1, xlsx_file))\n",
    "\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(f) Create a loop that ...\n",
    "\n",
    "- Reads multiple \".csv\" files\n",
    "- Creates a numeric vector by \n",
    "    - Adding/Subtracting/Mutiplying/Diving two or more variables \n",
    "- Plots a histogram of the transformed variable\n",
    "    - Numbers the figures\n",
    "    - Labels the axes\n",
    "    - Labels the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the .csv files are stored\n",
    "dir = \"/path/to/csv/files\"\n",
    "\n",
    "# List all .csv files in the directory\n",
    "csv_files = [f for f in os.listdir(dir) if f.endswith('.csv')]\n",
    "\n",
    "# Loop over all the .csv files\n",
    "for i, csv_file in enumerate(csv_files):\n",
    "    # Read the .csv file into a Pandas DataFrame\n",
    "    df = pd.read_csv( csv_file)\n",
    "    \n",
    "    # Perform operations on columns in the DataFrame to create a new vector\n",
    "    vec = df[\"col1\"] + df[\"col2\"] * df[\"col3\"] / (df[\"col4\"] - df[\"col5\"])\n",
    "    \n",
    "    # Plot the histogram of the transformed vector\n",
    "    plt.figure(i + 1)\n",
    "    plt.hist(vec, bins=30)\n",
    "    \n",
    "    # Label the axes and title\n",
    "    plt.xlabel(\"Transformed Variable\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Histogram of Transformed Variable {}\".format(i + 1))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
